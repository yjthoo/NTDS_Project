{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTDS demo 6: web APIs & data analysis with pandas\n",
    "[Michaël Defferrard](http://deff.ch), *PhD student*, [EPFL](http://epfl.ch) [LTS2](http://lts2.epfl.ch)\n",
    "\n",
    "For this tutorial, we'll use the [PyGSP](https://github.com/epfl-lts2/pygsp), a Python package to ease signal processing on graphs.\n",
    "The PyGSP facilitates a wide variety of operations on graphs, like computing their Fourier basis, filtering or interpolating signals, plotting graphs, signals, and filters. The package includes a wide range of graphs and many filter banks. Despite all the pre-defined models, you can easily use a custom graph by defining its adjacency matrix, and a custom filter bank by defining a set of functions in the spectral domain.\n",
    "\n",
    "You will first need to install it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install pygsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygsp import graphs, filters, plotting\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "plotting.BACKEND = 'matplotlib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs are created with the [graphs module](https://pygsp.readthedocs.io/en/stable/reference/graphs.html). It includes a wide range of graphs, from point clouds like the Stanford bunny and the Swiss roll; to networks like the Minnesota road network; to models for generating random graphs like stochastic block models, sensor networks, Erdős–Rényi model, Barabási-Albert model; to simple graphs like the path, the ring, and the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = graphs.Minnesota()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided the chosen model sets coordinates for 2D or 3D plotting, the graph can be plotted with the `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Custom graphs and properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the [graphs module](https://pygsp.readthedocs.io/en/stable/reference/graphs.html) defines many graphs, we can easily use a custom graph by defining its adjacency matrix. The alternative is to provide features from which node similarities will be computed to form a sparse adjacency matrix (see `graphs.NNGraph`).\n",
    "\n",
    "Let's create a random weighted adjacency matrix and look at some properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.random.uniform(size=(300, 300))  # Full graph.\n",
    "W[W < 0.93] = 0  # Sparse graph.\n",
    "W = W + W.T  # Symmetric graph.\n",
    "np.fill_diagonal(W, 0)  # No self-loops.\n",
    "\n",
    "G = graphs.Graph(W)\n",
    "print('{} nodes, {} edges'.format(G.N, G.Ne))\n",
    "\n",
    "print('Connected: {}'.format(G.is_connected()))\n",
    "print('Directed: {}'.format(G.is_directed()))\n",
    "\n",
    "plt.hist(G.d)\n",
    "plt.title('Degree distribution of my random graph');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Exercise: layout\n",
    "\n",
    "Coordinates are sometimes given, e.g. if the graph is a road network as above. If it's not the case, e.g. because we just have an adjacency matrix, we must assign coordinates before plotting in 2 or 3 dimension.\n",
    "\n",
    "A [layout method](https://en.wikipedia.org/wiki/Graph_drawing) is an algorithm to embed a graph in 2D for the purpose of drawing.\n",
    "\n",
    "Use the `set_coordinates` method to assign a 2D coordinate to each node of the below Barabasi-Albert graph. Use two strategies:\n",
    "1. place the nodes on a ring with `ring2D` and\n",
    "2. use a [force-directed layout](https://en.wikipedia.org/wiki/Force-directed_graph_drawing) with `spring`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = graphs.BarabasiAlbert(N=100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "# Your code here.\n",
    "G.plot(ax=axes[0])\n",
    "\n",
    "# Your code here.\n",
    "G.plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Laplacians\n",
    "\n",
    "Let's create a community graph composed of `Nc=3` communities of 50, 120, and 80 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "communities = [50, 120, 80]\n",
    "G = graphs.Community(N=250, Nc=3, comm_sizes=communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That graph is binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.unique(G.W.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize it in two ways:\n",
    "1. the sparsity pattern of its adjacency matrix `G.W` and\n",
    "1. its node-link diagram.\n",
    "\n",
    "Remember, visualizing data is often insightful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "_ = axes[0].spy(G.W, markersize=0.5)\n",
    "G.set_coordinates('community2D')\n",
    "G.plot(ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the combinatorial Laplacian $L = D - W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.compute_laplacian('combinatorial')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].spy(G.L, markersize=0.6)\n",
    "axes[1].hist(G.L.data, bins=50, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the normalized Laplacian $L = I - D^{-1/2} W D^{-1/2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.compute_laplacian('normalized')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].spy(G.L, markersize=0.6)\n",
    "axes[1].hist(G.L.data, bins=50, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Graph signals\n",
    "\n",
    "A graph signal $x: \\mathcal{V} \\rightarrow \\mathbb{R}$ can be seen as a vector $x \\in \\mathbb{R}^N$, where $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Let's first create a random signal and visualize it on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(-1, 1, size=G.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.plot_signal(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it smooth? Our intuition certainly says no. Let's verify by computing $$x^T L x = \\sum_{i \\sim j} W_{ij} (x_i - x_j)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.T @ G.L @ x / np.linalg.norm(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare it with the partitioning function:\n",
    "$$ x[i] =\n",
    "\\begin{cases}\n",
    "    -1 &\\text{if } i \\in S_1, \\\\\n",
    "    0  &\\text{if } i \\in S_2, \\\\\n",
    "    1  &\\text{if } i \\in S_3,\n",
    "\\end{cases}\n",
    "$$\n",
    "where $S_i$ is the set of nodes in partition $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros(G.N)\n",
    "x[:communities[0]] = -1 * np.ones(communities[0])\n",
    "x[-communities[-1]:] = 1 * np.ones(communities[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G.plot_signal(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.T @ G.L @ x / np.linalg.norm(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function is certainly smoother!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exercise\n",
    "\n",
    "What is the smoothest non-trivial signal?\n",
    "$$\\min_x x^T L x, \\text{ s.t. } x \\neq 0 \\text{ and } x^T D^{1/2}1 = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not the null signal.\n",
    "x0 = np.zeros(G.N)\n",
    "x0.T @ G.L @ x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not the \"constant\" signal either.\n",
    "if G.lap_type == 'combinatorial':\n",
    "    x1 = np.ones(G.N)\n",
    "elif G.lap_type == 'normalized':\n",
    "    x1 = np.power(G.d, 0.5) * np.ones(G.N)\n",
    "\n",
    "x1.T @ G.L @ x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = # Your code here.\n",
    "\n",
    "print(x.T @ x1)\n",
    "x.T @ G.L @ x / np.linalg.norm(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gradient and divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Fourier basis\n",
    "\n",
    "The PyGSP allows to compute the Fourier basis with the `compute_fourier_basis()` method. Remember that this involves the full eigendecomposition of the Laplacian which costs $\\mathcal{O}(N^3)$ in general.\n",
    "\n",
    "As expected, the GFT on a ring graph is equal to classical Fourier modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = graphs.Ring(N=50)\n",
    "G.compute_fourier_basis()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "G.plot_signal(G.U[:, 4], ax=axes[0])\n",
    "\n",
    "G.set_coordinates('line1D')\n",
    "G.plot_signal(G.U[:, 1:4], ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Exercise\n",
    "\n",
    "Plot the first 7 Fourier modes of the grid and a sensor network. What do you observe?\n",
    "\n",
    "**Your answer here.**\n",
    "\n",
    "Hints:\n",
    "* Use `G = graphs.Grid2d(10, 10)` and `G = graphs.Sensor(seed=42)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Graph Fourier Transform\n",
    "\n",
    "The graph Fourier transform (GFT) of a signal $x$ is given by\n",
    "$$\\hat{x} = U^T x,$$\n",
    "where $U$ is the graph Fourier basis.\n",
    "\n",
    "The inverse Fourier transform is given by\n",
    "$$x = U \\hat{x}.$$\n",
    "\n",
    "The intuition about the smoothness of a signal and its representation in the spectral domain again transfers from classical Fourier analysis. Look a the below figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = graphs.Sensor(seed=42)\n",
    "G.compute_fourier_basis()\n",
    "\n",
    "taus = [0, 3, 10]\n",
    "fig, axes = plt.subplots(len(taus), 2, figsize=(17, 9))\n",
    "\n",
    "x0 = np.random.RandomState(1).normal(size=G.N)\n",
    "for i, tau in enumerate(taus):\n",
    "    g = filters.Heat(G, tau)\n",
    "    x = g.filter(x0).squeeze()\n",
    "    x_hat = G.gft(x).squeeze()\n",
    "    \n",
    "    G.plot_signal(x, ax=axes[i, 0])\n",
    "    axes[i, 0].set_axis_off()\n",
    "    axes[i, 0].set_title('')\n",
    "    axes[i, 0].text(0, -0.2, '$x^T L x = {:.2f}$'.format(x.T @ G.L @ x))\n",
    "    \n",
    "    axes[i, 1].plot(G.e, np.abs(x_hat), '.-')\n",
    "    \n",
    "axes[0, 0].set_title(r'$x$: signal in the vertex domain')\n",
    "axes[0, 1].set_title(r'$\\hat{x}$: signal in the spectral domain')\n",
    "axes[-1, 1].set_xlabel(\"laplacian's eigenvalues / graph frequencies\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Filtering\n",
    "\n",
    "A graph signal is filterd as\n",
    "$$y = U g(\\Lambda) U^T x = g(L) x,$$\n",
    "where $g$ is the filter kernel.\n",
    "\n",
    "In general, we try to avoid the need to compute the Fourier basis by defining filters as polynomials of the graph Laplacian. As long as you can specify your filter $g(\\cdot)$ as a continuous function of the eigenvalues $\\lambda$, the PyGSP will take care of computing the coefficients of the best approximating [Chebyshev polynomials](https://en.wikipedia.org/wiki/Chebyshev_polynomials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1 = graphs.Sensor(seed=42)\n",
    "G1.compute_fourier_basis()\n",
    "G2 = graphs.Ring(N=100)\n",
    "G2.compute_fourier_basis()\n",
    "G2.set_coordinates('line1D')\n",
    "\n",
    "TAUS = [0, 5, 100]\n",
    "DELTA = 10\n",
    "\n",
    "fig, axes = plt.subplots(len(TAUS), 3, figsize=(17, 7))\n",
    "\n",
    "for i, tau in enumerate(TAUS):\n",
    "    g1 = filters.Heat(G1, tau)\n",
    "    g2 = filters.Heat(G2, tau)\n",
    "    \n",
    "    y = g1.localize(DELTA).squeeze()\n",
    "    G1.plot_signal(y, ax=axes[i, 0])\n",
    "    axes[i, 0].set_axis_off()\n",
    "    axes[i, 0].set_title('')\n",
    "    axes[i, 0].text(0, -0.2, '$y^T L y = {:.2f}$'.format(y.T @ G1.L @ y))\n",
    "    \n",
    "    G2.plot_signal(g2.localize(G2.N//2), ax=axes[i, 2])\n",
    "    axes[i, 2].set_title('')\n",
    "    \n",
    "    g1.plot(ax=axes[i, 1])\n",
    "    axes[i, 1].set_xlabel('')\n",
    "    axes[i, 1].set_ylabel('')\n",
    "    text = r'$\\hat{{g}}(\\lambda) = \\exp \\left( \\frac{{-{{{}}} \\lambda}}{{\\lambda_{{max}}}} \\right)$'.format(tau)\n",
    "    axes[i, 1].text(6, 0.5, text, fontsize=15)\n",
    "    \n",
    "axes[0, 0].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on sensor'.format(DELTA))\n",
    "axes[0, 1].set_title('$\\hat{g}(\\lambda)$: filter defined in the spectral domain')\n",
    "axes[0, 2].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on ring graph'.format(G2.N//2))\n",
    "axes[-1, 1].set_xlabel(\"$\\lambda$: laplacian's eigenvalues / graph frequencies\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Exercise\n",
    "\n",
    "Look at the below code where we analyze a delta signal with two filter banks (`filters.MexicanHat` and `filters.Itersine`) and reconstruct it. How do you explain the difference in reconstruction error?\n",
    "\n",
    "**Your answer here.**\n",
    "\n",
    "Hints:\n",
    "* Look at the filters in the spectral domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = graphs.Sensor(30, seed=42)\n",
    "G.compute_fourier_basis()  # Reproducible computation of lmax.\n",
    "s1 = np.zeros(G.N)\n",
    "s1[13] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = filters.MexicanHat(G, Nf=4)\n",
    "s2 = g.analyze(s1)\n",
    "s2 = g.synthesize(s2)\n",
    "np.linalg.norm(s1 - s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = filters.Itersine(G, Nf=4)\n",
    "s2 = g.analyze(s1)\n",
    "s2 = g.synthesize(s2)\n",
    "np.linalg.norm(s1 - s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
